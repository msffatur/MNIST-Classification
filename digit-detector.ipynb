{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning dan Shallow Learning\n",
    "### Muhammad Shafwan Faturrahman (13316006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import data latih angka hingga siap olah \n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "(x_num_trn, y_num_trn),(x_num_test, y_num_test)= mnist.load_data()\n",
    "x_num_all = np.append(x_num_trn,x_num_test,axis=0)\n",
    "y_num_all = np.append(y_num_trn,y_num_test,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data latih huruf(A-J) hingga siap olah\n",
    "from emnist import extract_training_samples, extract_test_samples\n",
    "x_alp_trn, y_alp_trn = extract_training_samples('letters')\n",
    "x_alp_test, y_alp_test = extract_test_samples('letters')\n",
    "x_alp_trn = np.array(x_alp_trn[np.argwhere(y_alp_trn<=10),:,:])\n",
    "x_alp_trn = np.squeeze(x_alp_trn, axis = 1)\n",
    "y_alp_trn = np.array(y_alp_trn[np.argwhere(y_alp_trn<=10)]) + 9\n",
    "y_alp_trn = np.squeeze(y_alp_trn, axis = 1)\n",
    "x_alp_test = np.array(x_alp_test[np.argwhere(y_alp_test<=10),:,:])\n",
    "x_alp_test = np.squeeze(x_alp_test, axis = 1)\n",
    "y_alp_test = np.array(y_alp_test[np.argwhere(y_alp_test<=10)]) + 9\n",
    "y_alp_test = np.squeeze(y_alp_test, axis = 1)\n",
    "x_alp_all = np.append(x_alp_trn,x_alp_test,axis=0)\n",
    "y_alp_all = np.append(y_alp_trn,y_alp_test,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data gabungan angka dan huruf\n",
    "x_all = np.append(x_num_all,x_alp_all,axis=0)\n",
    "y_all = np.append(y_num_all,y_alp_all,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_trn, x_test, y_trn, y_test = train_test_split(x_all, y_all, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (88200, 28, 28, 1)\n",
      "88200 train samples\n",
      "37800 test samples\n"
     ]
    }
   ],
   "source": [
    "#Data format configuration\n",
    "import keras.backend as K\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_trn = x_trn.reshape(x_trn.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_trn = x_trn.reshape(x_trn.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "x_trn = x_trn.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_trn /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_trn.shape)\n",
    "print(x_trn.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classing\n",
    "import keras.utils as Ku\n",
    "num_class = 20\n",
    "y_trn = Ku.to_categorical(y_trn, num_class)\n",
    "y_test = Ku.to_categorical(y_test, num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Architecture\n",
    "#Deep Learning (CNN)\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "model_1 = Sequential()\n",
    "model_1.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model_1.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_1.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_1.add(Dropout(0.25))\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(784, activation='relu'))\n",
    "model_1.add(Dense(392, activation='relu'))\n",
    "model_1.add(Dense(196, activation='relu'))\n",
    "model_1.add(Dense(98, activation='relu'))\n",
    "model_1.add(Dense(49, activation='relu'))\n",
    "model_1.add(Dropout(0.5))\n",
    "model_1.add(Dense(num_class, activation='softmax'))\n",
    "model_1.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shallow Learning (NN)\n",
    "model_2 = Sequential()\n",
    "model_2.add(Flatten(input_shape=input_shape))\n",
    "model_2.add(Dense(98, activation='relu'))\n",
    "model_2.add(Dropout(0.5))\n",
    "model_2.add(Dense(num_class, activation='softmax'))\n",
    "model_2.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 784)               7226128   \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 392)               307720    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 196)               77028     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 98)                19306     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 49)                4851      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 49)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 20)                1000      \n",
      "=================================================================\n",
      "Total params: 7,654,849\n",
      "Trainable params: 7,654,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Summary model_1\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 98)                76930     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 98)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 20)                1980      \n",
      "=================================================================\n",
      "Total params: 78,910\n",
      "Trainable params: 78,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Summary model_2\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "from tensorflow.keras.callbacks import CSVLogger,EarlyStopping\n",
    "logfile_cnn = 'MNIST-CNN.log'\n",
    "logfile_nn = 'MNIST-NN.log'\n",
    "csv_logger_1 = CSVLogger(logfile_cnn, append=True)  \n",
    "csv_logger_2 = CSVLogger(logfile_nn, append=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 88200 samples, validate on 37800 samples\n",
      "Epoch 1/10\n",
      "88200/88200 [==============================] - 349s 4ms/step - loss: 0.5808 - accuracy: 0.8389 - val_loss: 0.2609 - val_accuracy: 0.9215\n",
      "Epoch 2/10\n",
      "88200/88200 [==============================] - 344s 4ms/step - loss: 0.2705 - accuracy: 0.9279 - val_loss: 0.1620 - val_accuracy: 0.9508\n",
      "Epoch 3/10\n",
      "88200/88200 [==============================] - 356s 4ms/step - loss: 0.1821 - accuracy: 0.9533 - val_loss: 0.1633 - val_accuracy: 0.9553\n",
      "Epoch 4/10\n",
      "88200/88200 [==============================] - 346s 4ms/step - loss: 0.1381 - accuracy: 0.9641 - val_loss: 0.1200 - val_accuracy: 0.9679\n",
      "Epoch 5/10\n",
      "88200/88200 [==============================] - 348s 4ms/step - loss: 0.1084 - accuracy: 0.9722 - val_loss: 0.1023 - val_accuracy: 0.9733\n",
      "Epoch 6/10\n",
      "88200/88200 [==============================] - 345s 4ms/step - loss: 0.0836 - accuracy: 0.9781 - val_loss: 0.0969 - val_accuracy: 0.9784\n",
      "Epoch 7/10\n",
      "88200/88200 [==============================] - 344s 4ms/step - loss: 0.0728 - accuracy: 0.9811 - val_loss: 0.1167 - val_accuracy: 0.9724\n",
      "Epoch 8/10\n",
      "88200/88200 [==============================] - 348s 4ms/step - loss: 0.0581 - accuracy: 0.9846 - val_loss: 0.1134 - val_accuracy: 0.9757\n",
      "Epoch 9/10\n",
      "88200/88200 [==============================] - 354s 4ms/step - loss: 0.0481 - accuracy: 0.9868 - val_loss: 0.1170 - val_accuracy: 0.9748\n",
      "Epoch 10/10\n",
      "88200/88200 [==============================] - 345s 4ms/step - loss: 0.0438 - accuracy: 0.9884 - val_loss: 0.0978 - val_accuracy: 0.9792\n",
      "Test loss: 0.09781673810364025\n",
      "Test accuracy: 0.9792063236236572\n"
     ]
    }
   ],
   "source": [
    "#Fit model_1\n",
    "model_1.fit(x_trn, y_trn,\n",
    "          batch_size=512,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[csv_logger_1,early_stopping]\n",
    "          )\n",
    "score = model_1.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 88200 samples, validate on 37800 samples\n",
      "Epoch 1/100\n",
      "88200/88200 [==============================] - 3s 31us/step - loss: 0.3822 - accuracy: 0.8834 - val_loss: 0.2267 - val_accuracy: 0.9341\n",
      "Epoch 2/100\n",
      "88200/88200 [==============================] - 3s 38us/step - loss: 0.3771 - accuracy: 0.8839 - val_loss: 0.2266 - val_accuracy: 0.9339\n",
      "Epoch 3/100\n",
      "88200/88200 [==============================] - 3s 32us/step - loss: 0.3753 - accuracy: 0.8855 - val_loss: 0.2219 - val_accuracy: 0.9343\n",
      "Epoch 4/100\n",
      "88200/88200 [==============================] - 3s 35us/step - loss: 0.3707 - accuracy: 0.8869 - val_loss: 0.2229 - val_accuracy: 0.9349\n",
      "Epoch 5/100\n",
      "88200/88200 [==============================] - 3s 33us/step - loss: 0.3689 - accuracy: 0.8858 - val_loss: 0.2213 - val_accuracy: 0.9341\n",
      "Epoch 6/100\n",
      "88200/88200 [==============================] - 3s 34us/step - loss: 0.3647 - accuracy: 0.8875 - val_loss: 0.2195 - val_accuracy: 0.9353\n",
      "Epoch 7/100\n",
      "88200/88200 [==============================] - 3s 36us/step - loss: 0.3625 - accuracy: 0.8890 - val_loss: 0.2200 - val_accuracy: 0.9364\n",
      "Epoch 8/100\n",
      "88200/88200 [==============================] - 3s 33us/step - loss: 0.3607 - accuracy: 0.8880 - val_loss: 0.2173 - val_accuracy: 0.9366\n",
      "Epoch 9/100\n",
      "88200/88200 [==============================] - 3s 35us/step - loss: 0.3586 - accuracy: 0.8894 - val_loss: 0.2160 - val_accuracy: 0.9366\n",
      "Epoch 10/100\n",
      "88200/88200 [==============================] - 3s 34us/step - loss: 0.3600 - accuracy: 0.8885 - val_loss: 0.2153 - val_accuracy: 0.9372\n",
      "Epoch 11/100\n",
      "88200/88200 [==============================] - 3s 38us/step - loss: 0.3553 - accuracy: 0.8907 - val_loss: 0.2143 - val_accuracy: 0.9366\n",
      "Epoch 12/100\n",
      "88200/88200 [==============================] - 3s 35us/step - loss: 0.3519 - accuracy: 0.8904 - val_loss: 0.2135 - val_accuracy: 0.9372\n",
      "Epoch 13/100\n",
      "88200/88200 [==============================] - 3s 36us/step - loss: 0.3527 - accuracy: 0.8910 - val_loss: 0.2157 - val_accuracy: 0.9364\n",
      "Epoch 14/100\n",
      "88200/88200 [==============================] - 3s 32us/step - loss: 0.3475 - accuracy: 0.8925 - val_loss: 0.2121 - val_accuracy: 0.9388\n",
      "Epoch 15/100\n",
      "88200/88200 [==============================] - 3s 37us/step - loss: 0.3486 - accuracy: 0.8922 - val_loss: 0.2133 - val_accuracy: 0.9388\n",
      "Epoch 16/100\n",
      "88200/88200 [==============================] - 3s 34us/step - loss: 0.3444 - accuracy: 0.8942 - val_loss: 0.2114 - val_accuracy: 0.9380\n",
      "Epoch 17/100\n",
      "88200/88200 [==============================] - 3s 36us/step - loss: 0.3433 - accuracy: 0.8937 - val_loss: 0.2096 - val_accuracy: 0.9388\n",
      "Epoch 18/100\n",
      "88200/88200 [==============================] - 3s 34us/step - loss: 0.3369 - accuracy: 0.8946 - val_loss: 0.2114 - val_accuracy: 0.9379\n",
      "Epoch 19/100\n",
      "88200/88200 [==============================] - 3s 36us/step - loss: 0.3407 - accuracy: 0.8945 - val_loss: 0.2115 - val_accuracy: 0.9390\n",
      "Epoch 20/100\n",
      "88200/88200 [==============================] - 3s 34us/step - loss: 0.3374 - accuracy: 0.8943 - val_loss: 0.2076 - val_accuracy: 0.9394\n",
      "Epoch 21/100\n",
      "88200/88200 [==============================] - 3s 36us/step - loss: 0.3400 - accuracy: 0.8944 - val_loss: 0.2071 - val_accuracy: 0.9394\n",
      "Epoch 22/100\n",
      "88200/88200 [==============================] - 3s 34us/step - loss: 0.3384 - accuracy: 0.8955 - val_loss: 0.2065 - val_accuracy: 0.9395\n",
      "Epoch 23/100\n",
      "88200/88200 [==============================] - 3s 37us/step - loss: 0.3343 - accuracy: 0.8952 - val_loss: 0.2068 - val_accuracy: 0.9398\n",
      "Epoch 24/100\n",
      "88200/88200 [==============================] - 3s 36us/step - loss: 0.3337 - accuracy: 0.8955 - val_loss: 0.2067 - val_accuracy: 0.9394\n",
      "Epoch 25/100\n",
      "88200/88200 [==============================] - 3s 37us/step - loss: 0.3296 - accuracy: 0.8974 - val_loss: 0.2056 - val_accuracy: 0.9398\n",
      "Epoch 26/100\n",
      "88200/88200 [==============================] - 3s 34us/step - loss: 0.3294 - accuracy: 0.8974 - val_loss: 0.2045 - val_accuracy: 0.9407\n",
      "Epoch 27/100\n",
      "88200/88200 [==============================] - 3s 36us/step - loss: 0.3284 - accuracy: 0.8975 - val_loss: 0.2062 - val_accuracy: 0.9400\n",
      "Epoch 28/100\n",
      "88200/88200 [==============================] - 3s 34us/step - loss: 0.3299 - accuracy: 0.8972 - val_loss: 0.2035 - val_accuracy: 0.9405\n",
      "Epoch 29/100\n",
      "88200/88200 [==============================] - 3s 39us/step - loss: 0.3245 - accuracy: 0.8992 - val_loss: 0.2046 - val_accuracy: 0.9394\n",
      "Epoch 30/100\n",
      "88200/88200 [==============================] - 3s 34us/step - loss: 0.3245 - accuracy: 0.8985 - val_loss: 0.2007 - val_accuracy: 0.9424\n",
      "Epoch 31/100\n",
      "88200/88200 [==============================] - 3s 38us/step - loss: 0.3230 - accuracy: 0.8991 - val_loss: 0.2012 - val_accuracy: 0.9415\n",
      "Epoch 32/100\n",
      "88200/88200 [==============================] - 3s 39us/step - loss: 0.3256 - accuracy: 0.8986 - val_loss: 0.2055 - val_accuracy: 0.9396\n",
      "Epoch 33/100\n",
      "88200/88200 [==============================] - 3s 37us/step - loss: 0.3241 - accuracy: 0.8989 - val_loss: 0.2002 - val_accuracy: 0.9428\n",
      "Epoch 34/100\n",
      "88200/88200 [==============================] - 3s 34us/step - loss: 0.3239 - accuracy: 0.8987 - val_loss: 0.2029 - val_accuracy: 0.9408\n",
      "Epoch 35/100\n",
      "88200/88200 [==============================] - 3s 37us/step - loss: 0.3154 - accuracy: 0.9027 - val_loss: 0.1996 - val_accuracy: 0.9424\n",
      "Epoch 36/100\n",
      "88200/88200 [==============================] - 4s 40us/step - loss: 0.3169 - accuracy: 0.9009 - val_loss: 0.1970 - val_accuracy: 0.9430\n",
      "Epoch 37/100\n",
      "88200/88200 [==============================] - 4s 42us/step - loss: 0.3191 - accuracy: 0.8998 - val_loss: 0.1998 - val_accuracy: 0.9425\n",
      "Epoch 38/100\n",
      "88200/88200 [==============================] - 3s 37us/step - loss: 0.3149 - accuracy: 0.9008 - val_loss: 0.2003 - val_accuracy: 0.9420\n",
      "Epoch 39/100\n",
      "88200/88200 [==============================] - 3s 38us/step - loss: 0.3179 - accuracy: 0.8998 - val_loss: 0.1994 - val_accuracy: 0.9422\n",
      "Epoch 40/100\n",
      "88200/88200 [==============================] - 3s 34us/step - loss: 0.3159 - accuracy: 0.9004 - val_loss: 0.1997 - val_accuracy: 0.9412\n",
      "Epoch 41/100\n",
      "88200/88200 [==============================] - 3s 39us/step - loss: 0.3135 - accuracy: 0.9012 - val_loss: 0.1998 - val_accuracy: 0.9424\n",
      "Epoch 00041: early stopping\n",
      "Test loss: 0.1998417741620036\n",
      "Test accuracy: 0.9424074292182922\n"
     ]
    }
   ],
   "source": [
    "#Fit model_2\n",
    "model_2.fit(x_trn, y_trn,\n",
    "          batch_size=512,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[csv_logger_2,early_stopping]\n",
    "          )\n",
    "score = model_2.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pengolahan data input\n",
    "from PIL import ImageOps as IO\n",
    "from numpy import asarray\n",
    "def fix_data(data_input):\n",
    "  width, height = data_input.size\n",
    "  left = 0.1*width\n",
    "  top = 0.1*height\n",
    "  right = 0.9*width\n",
    "  bottom = 0.9*height\n",
    "  cropped_data = data_input.crop((left, top, right, bottom))\n",
    "  GS_data = IO.grayscale(cropped_data)\n",
    "  inv_data = IO.invert(GS_data)\n",
    "  rsz_data = inv_data.resize((28,28))\n",
    "  fixed_data = asarray(rsz_data)\n",
    "  return fixed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data input\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "datasets_test = \"image-crop\"\n",
    "list_data = listdir(datasets_test)\n",
    "data_gmb = []\n",
    "for nama in list_data:\n",
    "  data_img = Image.open(datasets_test + \"/\" + nama)\n",
    "  data_img = fix_data(data_img)\n",
    "  data_gmb.append(data_img)\n",
    "data_gmb = asarray(data_gmb)\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    data_gmb = data_gmb.reshape(data_gmb.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    data_gmb = data_gmb.reshape(data_gmb.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediksi output gambar model_1\n",
    "pred_gmb_cnn = model_1.predict(data_gmb)\n",
    "class_gmb_cnn = []\n",
    "for i in range(len(data_gmb)):\n",
    "    class_pred_cnn = 0\n",
    "    for j in range(num_class-1):\n",
    "        if pred_gmb_cnn[i,j+1] > class_pred_cnn:\n",
    "            class_pred_cnn = j+1\n",
    "    class_gmb_cnn.append(class_pred_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediksi output gambar model_2\n",
    "pred_gmb_nn = model_2.predict(data_gmb)\n",
    "class_gmb_nn = []\n",
    "for i in range(len(data_gmb)): \n",
    "    class_pred_nn = 0\n",
    "    for j in range(num_class-1):\n",
    "        if pred_gmb_nn[i,j+1] > class_pred_nn:\n",
    "            class_pred_nn = j+1\n",
    "    class_gmb_nn.append(class_pred_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Membuat file prediksi gambar\n",
    "import pandas as pd\n",
    "import xlsxwriter as xw\n",
    "format_data = pd.read_csv('format-prediksi-submit.csv')\n",
    "wb = xw.Workbook('prediksi-submit.xlsx')\n",
    "ws = wb.add_worksheet('Jawaban Gambar')\n",
    "huruf = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
    "head_table = ['image_filename', 'output model_1', 'output model_2']\n",
    "for i in range(len(head_table)):\n",
    "    ws.write(0,i,head_table[i])\n",
    "pred_model_1 = class_gmb_cnn\n",
    "pred_model_2 = class_gmb_nn\n",
    "for i in range(len(data_gmb)):\n",
    "    if pred_model_1[i]<10:\n",
    "        jwb_model_1 = int(pred_model_1[i])\n",
    "    else:\n",
    "        jwb_model_1 = pred_model_1[i] - 10\n",
    "        jwb_model_1 = huruf[int(jwb_model_1)]\n",
    "    if pred_model_2[i]<10:\n",
    "        jwb_model_2 = int(pred_model_2[i])\n",
    "    else:\n",
    "        jwb_model_2 = pred_model_2[i] - 10\n",
    "        jwb_model_2 = huruf[int(jwb_model_2)]\n",
    "    ws.write((i+1),0,str(format_data.iloc[i,0]))\n",
    "    ws.write((i+1),1,jwb_model_1)\n",
    "    ws.write((i+1),2,jwb_model_2)\n",
    "wb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_filename</th>\n",
       "      <th>output model_1</th>\n",
       "      <th>output model_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001-00-00.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001-00-01.jpg</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0001-00-02.jpg</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001-00-03.jpg</td>\n",
       "      <td>D</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001-00-04.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5515</th>\n",
       "      <td>A101b-09-07.jpg</td>\n",
       "      <td>J</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5516</th>\n",
       "      <td>A101b-09-08.jpg</td>\n",
       "      <td>J</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5517</th>\n",
       "      <td>A101b-09-09.jpg</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5518</th>\n",
       "      <td>A101b-09-10.jpg</td>\n",
       "      <td>J</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5519</th>\n",
       "      <td>A101b-09-11.jpg</td>\n",
       "      <td>J</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5520 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_filename output model_1 output model_2\n",
       "0      0001-00-00.jpg              0              B\n",
       "1      0001-00-01.jpg              B              B\n",
       "2      0001-00-02.jpg              D              D\n",
       "3      0001-00-03.jpg              D              B\n",
       "4      0001-00-04.jpg              6              B\n",
       "...               ...            ...            ...\n",
       "5515  A101b-09-07.jpg              J              D\n",
       "5516  A101b-09-08.jpg              J              D\n",
       "5517  A101b-09-09.jpg              A              D\n",
       "5518  A101b-09-10.jpg              J              G\n",
       "5519  A101b-09-11.jpg              J              D\n",
       "\n",
       "[5520 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#File prediksi MNIST\n",
    "pred_file = pd.read_excel('prediksi-submit.xlsx')\n",
    "pred_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Dalam menentukan perbedaan beberapa karakteristik dari kedua model training maka digunakan Convolutional Neural Network (CNN) model untuk deep learning dan 1 Layer Neural Network (NN) untuk shallow learning. Bentuk architecture kedua model dapat dilihat diatas pada bagian model.summary(). Berdasarkan data yang ditunjukan pada saat training dilakukan dapat dilihat bahwa deep learning dengan metode CNN memiliki kecepatan yang lebih lama daripada shallow learning dengan metode NN. Waktu yang dibutuhkan untuk setiap epochnya dapat dilihat diatas bahwa untuk metode CNN (deep learning) memerlukan waktu kurang lebih sekitar 350 detik, sedangkan untuk metode NN (shallow learning) hanya memerlukan waktu 3 hingga 4 detik saja. Hal ini tentunya dipengaruhi oleh banyaknya parameter yang digunakan pada model architecture yang digunakan. Jumlah parameter yang terbentuk tentunya jauh berbeda sehingga memberikan perbedaan waktu yang cukup signifikan. Hal ini juga yang menjadikan ukuran model CNN (deep learning) tentunya memerlukan memori penyimpanan yang lebih besar daripada NN (shallow learning). Jumlah parameter yang terdapat pada kedua model dapat dilihat sebagai berikut.\n",
    "   CNN = 7,654,849 params\n",
    "   NN  = 78,910 params\n",
    "   Akurasi yang dihasilkan oleh kedua metode tersebut tentunya akan berbeda pula. Validation Accuracy pada metode CNN (deep learning) memiliki angka yang lebih tinggi daripada metode NN (shallow learning). Metode CNN (deep learning) memiliki val_accuracy sebesar 0.9792 sedangkan metode NN (shallow learning) hanya memiliki val_accuracy sebesar  0.9424. Jika dilihat angkanya maka kedua metode tersebut tidak memiliki val_accuracy yang tidak jauh beda, namun hasil yang didapatkan tentunya sangatlah berbeda seperti yang bisa dilihat diatas pada file prediksi yang telah dibuat. Untuk kecepatan prediksi model tidak dapat diketahui berapa lama waktu yang dibutuhkan untuk kedua model, namun pada saat menjalankan perintah prediksi tersebut tidak memerlukan waktu yang lama untuk kedua model. \n",
    "   Berdasarkan beberapa data tersebut maka dapat disimpulkan kedua model training memiliki kelebihan masing-masing baik dari kecepatan operasi dan juga akurasi hasil yan didapatkan. Hal itu dapat dilihat dari beberapa parameter yang telah dibahas seperti ukuran model, kecepatan training dan akurasinya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
